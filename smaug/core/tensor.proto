syntax = "proto3";

package smaug;

import "smaug/core/types.proto";

message TensorShapeProto {
  repeated int32 dims = 1;
  DataLayout layout = 2;
  int32 alignment = 3;
}

message TensorProto {
  string name = 1;
  DataType data_type = 2;
  TensorShapeProto shape = 3;
  DataStorageFormat data_format = 4;
  // When we create a graph in Python, this field is not set and instead, all
  // tensor data is stored in a TensorDataArray so that we can dump the topology
  // and parameters in two separate proto buffers. It gets set only from
  // Tensor::asTensorProto, where an intermediate tensor is required to be
  // materialized for a one-off use case.
  TensorData data = 5;
}

message TensorData {
  // The data stored in the tensor. Only the field with data_type will be set.

  string name = 1;

  // Float16. This will be used for quantization. Note that since protobuf has
  // no int16 type, we will pack two half-precision floats into one element
  // here.
  repeated int32 half_data = 2 [packed = true];

  // Float32.
  repeated float float_data = 3 [packed = true];

  // Float64.
  repeated double double_data = 4 [packed = true];

  // Int32
  repeated int32 int_data = 5 [packed = true];

  // Int64
  repeated int64 int64_data = 6 [packed = true];

  // Bool
  repeated bool bool_data = 7 [packed = true];
}

// The tensor data is stored separately from the TensorProto. Each TensorData
// message is linked to the corresponding tensors in network topology file by
// the tensor's name. Therefore, we can easily look at the network topology
// from a small txt file. It also enables us to compress the parameters.
message TensorDataArray {
  repeated TensorData data_array = 1;
}
